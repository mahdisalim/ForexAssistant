# ุฎูุงุตู ุฑูุฒุงูู ุจุงุฒุงุฑ - Daily Market Summary

## ๐ ุชูุถุญุงุช

ุงู ูฺฺฏ ุจู ุตูุฑุช ุฎูุฏฺฉุงุฑ:
1. **ุงุฒ 5 ููุจุน ุฎุจุฑ ูุนุชุจุฑ** ุงุฎุจุงุฑ ุฑุง ุฌูุนโุขูุฑ ูโฺฉูุฏ:
   - Investing.com
   - ForexFactory
   - DailyFX
   - FXStreet
   - ForexLive

2. **ุจุง ุงุณุชูุงุฏู ุงุฒ ููุด ูุตููุน** ุฎูุงุตู ุฌุงูุน ุชููุฏ ูโฺฉูุฏ ุดุงูู:
   - ุฎูุงุตู ุจุงุฒุงุฑ
   - ุชุญูู ุงูุชุตุงุฏ
   - ุชุญูู ุณุงุณ
   - ูุถุนุช ุจุงุฒุงุฑูุง ูุงู
   - ุชุชุฑูุง ููู
   - ุฑูุฏุงุฏูุง ูพุด ุฑู
   - ุญุงู ู ููุง ุจุงุฒุงุฑ

## ๐ ูุญูู ุงุณุชูุงุฏู

### ุงุฒ API:

```bash
# ุฎูุงุตู ุจู ุฒุจุงู ูุงุฑุณ
curl "http://localhost:8000/api/summary/?timeframe=H1&asset=USD&lang=fa"

# ุฎูุงุตู ุจู ุฒุจุงู ุงูฺฏูุณ
curl "http://localhost:8000/api/summary/?timeframe=H1&asset=EUR&lang=en"

# ุฎูุงุตู ุจู ุฒุจุงู ุนุฑุจ
curl "http://localhost:8000/api/summary/?timeframe=D1&asset=GBP&lang=ar"
```

### ูพุงุฑุงูุชุฑูุง:

| ูพุงุฑุงูุชุฑ | ุชูุถุญุงุช | ููุงุฏุฑ ููฺฉู | ูพุดโูุฑุถ |
|---------|---------|-------------|---------|
| `timeframe` | ุจุงุฒู ุฒูุงู ุชุญูู | M1, M5, M15, M30, H1, H4, D1, W1 | H1 |
| `asset` | ุฏุงุฑุง ููุฑุฏ ูุธุฑ | USD, EUR, GBP, JPY, XAU, BTC, ... | USD |
| `lang` | ุฒุจุงู ุฎูุงุตู | fa, en, ar, tr, de, fr, es, ru, zh, ja, ko, pt, it, hi | fa |

### ุฏุงุฑุงโูุง ูพุดุชุจุงู ุดุฏู:

**ุงุฑุฒูุง:**
- USD (ุฏูุงุฑ ุขูุฑฺฉุง)
- EUR (ูุฑู)
- GBP (ูพููุฏ ุงูฺฏูุณ)
- JPY (ู ฺุงูพู)
- CHF (ูุฑุงูฺฉ ุณูุฆุณ)
- AUD (ุฏูุงุฑ ุงุณุชุฑุงูุง)
- CAD (ุฏูุงุฑ ฺฉุงูุงุฏุง)
- NZD (ุฏูุงุฑ ููุฒููุฏ)
- CNY (ูุงู ฺู)

**ฺฉุงูุงูุง:**
- XAU (ุทูุง)
- XAG (ููุฑู)
- OIL (ููุช)

**ุดุงุฎุตโูุง:**
- SPX (S&P 500)
- DJI (Dow Jones)
- NDX (NASDAQ)

**ุฑูุฒุงุฑุฒูุง:**
- BTC (ุจุชโฺฉูู)
- ETH (ุงุชุฑูู)
- ู ุณุงุฑ ุฑูุฒุงุฑุฒูุง ุงุตู

## ๐ ููููู ูพุงุณุฎ:

```json
{
  "generated_at": "2025-12-20T16:20:32.185520",
  "articles_count": 45,
  "timeframe": "H1",
  "asset": "USD",
  "lang": "fa",
  "sources": [
    "Investing.com",
    "ForexFactory",
    "DailyFX",
    "FXStreet",
    "ForexLive"
  ],
  "summary": "**ุฎูุงุตู ุจุงุฒุงุฑ**: ุฏูุงุฑ ุขูุฑฺฉุง ุงูุฑูุฒ...",
  "success": true
}
```

## โ๏ธ ุชูุธูุงุช

ุจุฑุง ุงุณุชูุงุฏู ุงุฒ ุงู ูฺฺฏุ ุจุงุฏ ฺฉูุฏ API OpenAI ุฑุง ุฏุฑ ูุงู `.env` ุชูุธู ฺฉูุฏ:

```bash
OPENAI_API_KEY=your-api-key-here
```

## ๐ ุงุฌุฑุง ุฏุณุช Scraping

ุงฺฏุฑ ูโุฎูุงูุฏ ุจู ุตูุฑุช ุฏุณุช ุงุฎุจุงุฑ ุฑุง ุฌูุนโุขูุฑ ฺฉูุฏ:

```bash
# ูุงุฑุฏ ฺฉุงูุชูุฑ ุดูุฏ
docker compose -f /srv/deploy/docker-compose.yml exec web bash

# ุงุฌุฑุง scraper
python -c "
import asyncio
from scrapers.scraper_manager import ScraperManager
from pathlib import Path

async def main():
    manager = ScraperManager(Path('/app/data'))
    articles = await manager.scrape_all()
    print(f'Scraped {len(articles)} articles')

asyncio.run(main())
"
```

## ๐ ูฺฉุงุช ููู

1. **ุฒูุงู ูพุงุณุฎ**: ุงููู ุจุงุฑ ฺฉู ุงู endpoint ุฑุง ูุฑุงุฎูุงู ูโฺฉูุฏุ ููฺฉู ุงุณุช 30-60 ุซุงูู ุทูู ุจฺฉุดุฏ ฺูู ุจุงุฏ ุงุฒ 5 ููุจุน ุงุฎุจุงุฑ ุฑุง ุฌูุนโุขูุฑ ฺฉูุฏ.

2. **Cache**: ุจุฑุง ุจูุจูุฏ ุนููฺฉุฑุฏุ ูโุชูุงูุฏ ูุชุงุฌ ุฑุง cache ฺฉูุฏ.

3. **Rate Limiting**: ุจุฑุฎ ุงุฒ ุณุงุชโูุง ุฎุจุฑ ููฺฉู ุงุณุช ูุญุฏูุฏุช ุชุนุฏุงุฏ ุฏุฑุฎูุงุณุช ุฏุงุดุชู ุจุงุดูุฏ.

4. **ุฒุจุงูโูุง ูพุดุชุจุงู ุดุฏู**: ุณุณุชู ุงุฒ 14 ุฒุจุงู ูุฎุชูู ูพุดุชุจุงู ูโฺฉูุฏ.

## ๐ ุนุจโุงุจ

ุงฺฏุฑ ุฎุทุง ุฏุฑุงูุช ฺฉุฑุฏุฏ:

1. **ุจุฑุฑุณ ูุงฺฏโูุง:**
```bash
docker compose -f /srv/deploy/docker-compose.yml logs web --tail 100
```

2. **ุจุฑุฑุณ ฺฉูุฏ OpenAI:**
```bash
docker compose -f /srv/deploy/docker-compose.yml exec web env | grep OPENAI
```

3. **ุชุณุช ุฏุณุช scraper:**
```bash
docker compose -f /srv/deploy/docker-compose.yml exec web python -c "
from scrapers.investing_scraper import InvestingScraper
import asyncio
scraper = InvestingScraper()
articles = asyncio.run(scraper.scrape_news())
print(f'Found {len(articles)} articles')
"
```

## ๐ฎ ุชูุณุนู ุขูุฏู

- [ ] Cache ฺฉุฑุฏู ูุชุงุฌ ุจุฑุง ุจูุจูุฏ ุณุฑุนุช
- [ ] ุงุถุงูู ฺฉุฑุฏู ููุงุจุน ุฎุจุฑ ุจุดุชุฑ
- [ ] ูพุดุชุจุงู ุงุฒ ุชุญูู ุชฺฉูฺฉุงู ููุฑุงู ุจุง ุงุฎุจุงุฑ
- [ ] ุงุฑุณุงู ุฎูุงุตู ุฑูุฒุงูู ุจู ุงูู
- [ ] ูููุฏุงุฑูุง ุชุนุงูู
